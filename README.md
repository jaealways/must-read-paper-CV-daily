# must-read-paper-CV-daily
List of papers with recent trend in CV

## 2023
- [2023 CVPR](/2023/CVPR.md)



## Updated on 2024.01.24

# Must-read LIST

|Date|Title|Authors|PDF|TAGS|TLDR|
|---|---|---|---|---|---|
|**01-31**|**On Distillation of Guided Diffusion Models**|Z Chen et.al.|[2208.00277](https://arxiv.org/pdf/2208.00277.pdf)|CVPR'23, 3D reconstruction|**[]()**|
|**01-30**|**SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis**|Z Chen et.al.|[2208.00277](https://arxiv.org/pdf/2208.00277.pdf)|CVPR'23, 3D reconstruction|**[]()**|
|**01-29**|**High-Resolution Image Synthesis with Latent Diffusion Models**|Z Chen et.al.|[2208.00277](https://arxiv.org/pdf/2208.00277.pdf)|CVPR'22, 3D reconstruction|**[]()**|
|**01-28**|**DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation**|Z Chen et.al.|[2208.00277](https://arxiv.org/pdf/2208.00277.pdf)|CVPR'23, 3D reconstruction|**[]()**|
|**01-27**|**MIC: Masked Image Consistency for Context Enhanced Domain Adaptation**|Z Chen et.al.|[2208.00277](https://arxiv.org/pdf/2208.00277.pdf)|CVPR'23, 3D reconstruction|**[]()**|
|**01-26**|**Tri-Perspective View for Vision Based 3D Semantic Occupancy Prediction**|Z Chen et.al.|[2208.00277](https://arxiv.org/pdf/2208.00277.pdf)|CVPR'23, 3D reconstruction|**[]()**|
|**01-25**|**Cross-modal graph matching network for image-text retrieval**|Z Chen et.al.|[2208.00277](https://arxiv.org/pdf/2208.00277.pdf)|ACM'22, 3D reconstruction|**[]()**|
|**01-24**|**Three things everyone should know about Vision Transformers**|Z Chen et.al.|[2208.00277](https://arxiv.org/pdf/2208.00277.pdf)|ECCV'22, 3D reconstruction|**[]()**|
|**01-23**|**MetaFormer is Acutally What You Need for Vision**|Z Chen et.al.|[2208.00277](https://arxiv.org/pdf/2208.00277.pdf)|CVPR'22, 3D reconstruction|**[]()**|
|**01-22**|**CLIP: Learning Transferable Visual Models From Natural Language Supervision**|A Radford et.al.|[2208.00277](https://arxiv.org/pdf/2208.00277.pdf)|ICML'21, 3D reconstruction|**[]()**|
|**01-21**|**Variational Adversarial Active Learning**|Z Chen et.al.|[2208.00277](https://arxiv.org/pdf/2208.00277.pdf)|ICCV'19, 3D reconstruction|**[]()**|
|**01-20**|**FastViT: A Fast Hybrid Vision Transformer using Structural Reparameterization**|Z Chen et.al.|[2208.00277](https://arxiv.org/pdf/2208.00277.pdf)|ICCV'23, 3D reconstruction|**[]()**|
|**01-19**|**MobileNeRF: Exploiting the Polygon Rasterization Pipeline for Efficient Neural Field Rendering on Mobile Architectures**|Z Chen et.al.|[2208.00277](https://arxiv.org/pdf/2208.00277.pdf)|CVPR'23, 3D reconstruction|**[]()**|
|**01-18**|**ANYTEXT: MULTILINGUAL VISUAL TEXT GENERA-TION AND EDITING**|Y Tuo et.al.|[2311.03054](https://arxiv.org/pdf/2311.03054.pdf)|CVPR'23, Diffusion|**[]()**|
|**01-17**|**Visual Programming: Compositional visual reasoning without training**|T Gupta et.al.|[2211.11559](https://arxiv.org/pdf/2211.11559.pdf)|CVPR'23, Vision multi-task|**[]()**|
|**01-16**|**TOKEN MERGING: YOUR VIT BUT FASTER**|D Bolya et.al.|[2210.09461](https://arxiv.org/pdf/2210.09461.pdf)|ICLR'23, ViT|**[]()**|
|**01-15**|**BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation**|J Li et.al.|[2201.12086](https://arxiv.org/pdf/2201.12086.pdf)|ICLR'23, ViT|**[]()**|



